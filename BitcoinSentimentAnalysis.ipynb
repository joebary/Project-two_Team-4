{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35eb2df7",
   "metadata": {},
   "source": [
    "Bitcoin Sentiment Analysis - Google and Reddit EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15916ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2f4f0056425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_interaction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatabaseInteraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_series_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmissing_dates_by_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs_previous_high\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from data.db_interaction import DatabaseInteraction\n",
    "from data.time_series_functions import missing_dates_by_year, vs_previous_high\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a298d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatabaseInteraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ad394494c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import Google Trends and Reddit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseInteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgtrends_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gtrends'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomments_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DatabaseInteraction' is not defined"
     ]
    }
   ],
   "source": [
    "# Import Google Trends and Reddit data\n",
    "DI = DatabaseInteraction()\n",
    "\n",
    "gtrends_df = DI.query_to_df(DI.query_all_data('gtrends'))\n",
    "comments_df = DI.query_to_df(DI.query_all_data('comments'))\n",
    "posts_df = DI.query_to_df(DI.query_all_data('posts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2a7f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gtrends_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ea8ec17996f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgtrends_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gtrends_df' is not defined"
     ]
    }
   ],
   "source": [
    "gtrends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f978a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate dates from the posts data\n",
    "posts_df.drop_duplicates(inplace=True)\n",
    "posts_df.sort_values('date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2c50e",
   "metadata": {},
   "source": [
    "Add all time high columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gtrends timestamp to date, search for missing dates\n",
    "gtrends_df['date'] = gtrends_df['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all time high columns\n",
    "gtrends_df = vs_previous_high(gtrends_df, 'date', 'scaled_interest')\n",
    "gtrends_df = vs_previous_high(gtrends_df, 'date', 'scaled_interest', window=365)\n",
    "posts_df = vs_previous_high(posts_df, 'date', 'num_comments')\n",
    "posts_df = vs_previous_high(posts_df, 'date', 'num_comments', window=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8162aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add comparison to median columns\n",
    "gtrends_df = vs_previous_high(gtrends_df, 'date', 'scaled_interest', window=365, function='median')\n",
    "gtrends_df = vs_previous_high(gtrends_df, 'date', 'scaled_interest', function='median')\n",
    "posts_df = vs_previous_high(posts_df, 'date', 'num_comments', function='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7c85b",
   "metadata": {},
   "source": [
    "Activity by Date - Google Trends\n",
    "\n",
    "The main takeaway from the graphs below is that Google Interest is seriously skewed by a couple of huge days at the end of 2017. This skews the percentage of all-time high metric for all dates following 2017. To combat this, I will need to adjust the calculation for the percentage of all-time high feature. The goal is to have a somewhat normal distribution that will allow for better bucketing. Even adjusting to percentage of the one year high is not sufficient, as the 2018 data is still very skewed and unusable. I imagine that this would also have been a problem for the Reddit data, but the Daily Discussion threads were not started until after 2017, which now makes a lot of sense given the huge rise in Bitcoin interest.\n",
    "\n",
    "Ultimately, I achieved a more normal distribution by comparing the current daily interest to the prior year median rather than the prior year maximum. I may also engineer moving average features to further smooth out the noise. The end of 2017 was a crazy time in the life of Bitcoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_by_date(df, date_column, line_columns, title, xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    Plot line graph with date x-axis for a given dataframe.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20,7))\n",
    "    plt.suptitle(title, fontweight='bold', fontsize=22)\n",
    "    plt.grid(True)\n",
    "    for col in line_columns:\n",
    "        plt.plot(df[date_column], df[col], label=col)\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9feb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(df, x, title, xlim=None, ylim=None, hue=None, bins='auto'):\n",
    "    \"\"\"\n",
    "    Plot histogram with date x-axis for a given dataframe.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=[20, 6])\n",
    "    plt.suptitle(title, fontweight='bold', fontsize=22)\n",
    "    sns.histplot(data=df, x=x, hue=hue,  ax=ax, kde=True, bins=bins)\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.xlim(ylim)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31045576",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_by_date(gtrends_df, 'date', ['scaled_interest'], 'Google Interest by Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b74891",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_by_date(gtrends_df, 'date', ['scaled_interest_vs_ath'], 'Google Interest by Date - % of All-Time High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_by_date(gtrends_df, 'date', ['scaled_interest_vs_high_prior_max_365'], 'Google Interest by Date - % of One Year High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_by_date(gtrends_df, 'date', ['scaled_interest_vs_high_prior_median_365'], 'Google Interest by Date - % of Prior Year Median', ylim=(0,7.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f716278",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_by_date(gtrends_df, 'date', ['scaled_interest_vs_all_time_median'], 'Google Interest by Date - % of All Time Median', ylim=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689af243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(gtrends_df, \n",
    "               x='scaled_interest_vs_high_prior_median_365', \n",
    "               title='Daily Google Interest vs. Prior Year Median',\n",
    "               xlim=(0,7.5)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(gtrends_df, \n",
    "               x='scaled_interest_vs_all_time_median', \n",
    "               title='Daily Google Interest vs. All-Time Median',\n",
    "               xlim=(0,10),\n",
    "               bins=300\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9b5d4",
   "metadata": {},
   "source": [
    "Activity by Date - Reddit\n",
    "\n",
    "Unlike for Google Trends, it doesn't appear that the all-time high calculation requires adjustment for Reddit comments. This is because the Daily Discussion threads only began in January of 2018, after the madness of 2017 had died down. The beginning of the data (2018) is still skewed, because the all-time high calculations are working off of a very small subset of data. However, the shape of the graph is not too dissimilar from the Google Trends data, with the beginning of 2018 being high relative to the remainder of the data. I'll leave it for now and revisit if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af68aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "plt.suptitle('Reddit Comments by Date', fontweight='bold', fontsize=22)\n",
    "plt.grid(True)\n",
    "plt.plot(posts_df['date'], posts_df['num_comments']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4427c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "plt.suptitle('Reddit Comments by Date - % of All-Time High', fontweight='bold', fontsize=22)\n",
    "plt.grid(True)\n",
    "plt.plot(posts_df['date'], posts_df['num_comments_vs_ath']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b15502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "plt.suptitle('Reddit Comments by Date - % of All-Time Median', fontweight='bold', fontsize=22)\n",
    "plt.grid(True)\n",
    "plt.plot(posts_df['date'], posts_df['num_comments_vs_all_time_median']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(posts_df, \n",
    "               x='num_comments_vs_ath', \n",
    "               title='Daily Reddit Activity vs. All-Time High'\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087899c8",
   "metadata": {},
   "source": [
    "Search for Missing Dates\n",
    "\n",
    "As you'll see below, missing dates is not a significant issue. From the 3.5 year history of reddit discussion threads, only 3 days are missing. I'll impute some date for these missing records. As for Google Trends, there are predictably no days missing from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing dates in reddit posts\n",
    "posts_missing_dates, posts_missing_df = missing_dates_by_year(posts_df, 'date', 'title')\n",
    "posts_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddeb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdecb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing dates in gtrends\n",
    "gtrends_missing_dates, gtrends_missing_df = missing_dates_by_year(gtrends_df, 'date', 'scaled_interest')\n",
    "gtrends_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b76f27",
   "metadata": {},
   "source": [
    "Filter Activity Data to Modeling Columns and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df539293",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrends_modeling_data = gtrends_df[['date', 'scaled_interest_vs_high_prior_median_365', 'scaled_interest_vs_all_time_median']].dropna()[1:]\n",
    "gtrends_modeling_data.columns = ['date', 'interest_vs_py_median', 'interest_vs_all_time_median']\n",
    "\n",
    "gtrends_modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ae4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_modeling_data = posts_df[['date', 'num_comments_vs_ath']]\n",
    "activity_data = gtrends_modeling_data.merge(posts_modeling_data, how='left', on='date')\n",
    "\n",
    "activity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfa2a7",
   "metadata": {},
   "source": [
    "Clean Comments Data - Remove Stickied Comments and Bots\n",
    "\n",
    "After manual inspection of the comments with \"bot\" anywhere in the author name, it appears that bots are not a significant problem in the r/Bitcoin Daily Discussion threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out stickied comments\n",
    "comments_df = comments_df[comments_df['stickied'] == False]\n",
    "\n",
    "# Check for bot accounts\n",
    "potential_bots = [x for x in list(comments_df['author'].str.lower().unique()) if 'bot' in x]\n",
    "bot_check = comments_df[comments_df['author'].isin(potential_bots)]\n",
    "\n",
    "bot_check.groupby('author')['timestamp'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282eba0",
   "metadata": {},
   "source": [
    "Pickle Google and Reddit Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the data for use in modeling\n",
    "with open('sentiment_pickles/pickle_activity_data.pickle', 'wb') as to_write:\n",
    "    pickle.dump(activity_data, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcb2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
